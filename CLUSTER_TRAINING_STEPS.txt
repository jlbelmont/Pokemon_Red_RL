Cluster Training & Environment Setup
====================================

1. Install Miniconda (one time)
--------------------------------
```
cd ~
curl -LO https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh -b -p "$HOME/miniconda3"
rm Miniconda3-latest-Linux-x86_64.sh
```

2. Initialize conda for bash
----------------------------
```
source "$HOME/miniconda3/etc/profile.d/conda.sh"
export CONDA_ENVS_DIRS="$HOME/conda_envs"
export CONDA_PKGS_DIRS="$HOME/conda_pkgs"
mkdir -p "$CONDA_ENVS_DIRS" "$CONDA_PKGS_DIRS"
```

3. Create the project env & install deps
----------------------------------------
```
conda create -n poke python=3.10 -y
conda activate poke
cd ~/projects/Final
pip install -r requirements.txt
```

4. Start a GPU session (max 4h)
--------------------------------
```
qlogin-gpu -g 20    # request 20GB GPU RAM (use 10/4/2 if preferred)
```

5. Launch headless training (each session)
------------------------------------------
```
source "$HOME/miniconda3/etc/profile.d/conda.sh"
conda activate poke
cd ~/projects/Final
chmod +x cluster_train.sh   # first run only
./cluster_train.sh
```

6. Repeat training chunks
-------------------------
When the 4h session ends, run steps 4â€“5 again. `cluster_train.sh` resumes from the newest checkpoint automatically.

7. Watch locally afterwards
---------------------------
On your laptop (with the repo synced):
```
./watch_local.sh
```
This loads the latest checkpoint in watch-only mode with aggregate map + gameplay grid.
